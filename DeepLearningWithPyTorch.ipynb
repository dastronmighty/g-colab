{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningWithPyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOY++r5BhqW9wUciVc9eBpd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5f68e2b186ff434285277ad4f5ec7510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntTextModel",
          "state": {
            "_view_name": "IntTextView",
            "style": "IPY_MODEL_4e44a13d8c1946fa913bc1474e7d8e32",
            "_dom_classes": [],
            "description": "Random Seed:",
            "_model_name": "IntTextModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 42,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": false,
            "step": 1,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b4a080be99d47c8bbbf32abe0933fc6"
          }
        },
        "4e44a13d8c1946fa913bc1474e7d8e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b4a080be99d47c8bbbf32abe0933fc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "073983c2bc48450a9a359e74647cc38a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "state": {
            "_view_name": "IntSliderView",
            "style": "IPY_MODEL_a28dbc40daa148218952b745179fead9",
            "_dom_classes": [],
            "description": "Epochs",
            "step": 1,
            "_model_name": "IntSliderModel",
            "orientation": "horizontal",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 15,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "min": 1,
            "continuous_update": true,
            "readout_format": "d",
            "description_tooltip": null,
            "readout": true,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b180803629c0444d96c133ab09910d8f"
          }
        },
        "a28dbc40daa148218952b745179fead9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "state": {
            "_view_name": "StyleView",
            "handle_color": null,
            "_model_name": "SliderStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b180803629c0444d96c133ab09910d8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6561d71fc9b04b189729e376f90b5957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatSliderModel",
          "state": {
            "_view_name": "FloatSliderView",
            "style": "IPY_MODEL_10a2651b31234f9b9a171ebcf4006491",
            "_dom_classes": [],
            "description": "Learning Rate:",
            "step": 0.001,
            "_model_name": "FloatSliderModel",
            "orientation": "horizontal",
            "max": 0.999,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0.001,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "min": 0.001,
            "continuous_update": true,
            "readout_format": ".3f",
            "description_tooltip": null,
            "readout": true,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b956a07417f425dbc6a2b198624a1d9"
          }
        },
        "10a2651b31234f9b9a171ebcf4006491": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "state": {
            "_view_name": "StyleView",
            "handle_color": null,
            "_model_name": "SliderStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b956a07417f425dbc6a2b198624a1d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f09940ef98ad4950a0474dc95d880e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntSliderModel",
          "state": {
            "_view_name": "IntSliderView",
            "style": "IPY_MODEL_7ea7bd3597324f6fb5c283331c534c96",
            "_dom_classes": [],
            "description": "Batch Size",
            "step": 32,
            "_model_name": "IntSliderModel",
            "orientation": "horizontal",
            "max": 1024,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 64,
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "min": 32,
            "continuous_update": true,
            "readout_format": "d",
            "description_tooltip": null,
            "readout": true,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8cebd8605edd456bb300e0aebe453f17"
          }
        },
        "7ea7bd3597324f6fb5c283331c534c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SliderStyleModel",
          "state": {
            "_view_name": "StyleView",
            "handle_color": null,
            "_model_name": "SliderStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8cebd8605edd456bb300e0aebe453f17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dastronmighty/g-colab/blob/main/DeepLearningWithPyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcAZwZG4qy5d"
      },
      "source": [
        "# PyTorch Ultra Document\n",
        "\n",
        "## with added memes\n",
        "\n",
        "### How does the math and s**t even work?\n",
        "\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1600/1*3tX5wuhfLPeinWsdEemi3Q.jpeg\" width=500 />\n",
        "\n",
        "and he is correct. Later on we gonna do some GPU magiké but for now lets stick \n",
        "with the basics\n",
        "\n",
        "sidenote im following [this](https://pytorch.org/tutorials/beginner/nn_tutorial.html) but im doing it better "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaPDq9wbVltu"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTQwcheGnWtA"
      },
      "source": [
        "! pip install -q  torchviz"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_ToeO6pFHFY"
      },
      "source": [
        "! pip install -q hiddenlayer"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARSa00Yvq6D1"
      },
      "source": [
        "import math # quick maths\n",
        "\n",
        "import time\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd #for good luck (who knows we might need it)\n",
        "\n",
        "\n",
        "# The Golden Child\n",
        "import torch\n",
        "\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "from torchviz import make_dot\n",
        "\n",
        "import hiddenlayer as hl\n",
        "\n",
        "\n",
        "from IPython.core.debugger import set_trace # debug time (now imagine toby mcguire saying it)\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140,
          "referenced_widgets": [
            "5f68e2b186ff434285277ad4f5ec7510",
            "4e44a13d8c1946fa913bc1474e7d8e32",
            "6b4a080be99d47c8bbbf32abe0933fc6",
            "073983c2bc48450a9a359e74647cc38a",
            "a28dbc40daa148218952b745179fead9",
            "b180803629c0444d96c133ab09910d8f",
            "6561d71fc9b04b189729e376f90b5957",
            "10a2651b31234f9b9a171ebcf4006491",
            "6b956a07417f425dbc6a2b198624a1d9",
            "f09940ef98ad4950a0474dc95d880e8d",
            "7ea7bd3597324f6fb5c283331c534c96",
            "8cebd8605edd456bb300e0aebe453f17"
          ]
        },
        "id": "u2icDL-VDeT4",
        "outputId": "9c5c8b8f-e16b-4e29-f371-d46a48e0989a"
      },
      "source": [
        "random_s_in = widgets.IntText(value=42,description='Random Seed:',disabled=False,style={'description_width': 'initial'})\n",
        "epoch_slider = widgets.IntSlider(value=15, min=1,max=100, description=\"Epochs\",style={'description_width': 'initial'})\n",
        "learning_weight = widgets.FloatSlider(value=0.001,min=0.001,max=0.999,step=0.001,description='Learning Rate:',readout=True,readout_format='.3f',style={'description_width': 'initial'})\n",
        "batch_slider = widgets.IntSlider(value=64, min=32,max=1024, step=32,description=\"Batch Size\",style={'description_width': 'initial'})\n",
        "display(random_s_in, epoch_slider, learning_weight, batch_slider)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f68e2b186ff434285277ad4f5ec7510",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "IntText(value=42, description='Random Seed:', style=DescriptionStyle(description_width='initial'))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "073983c2bc48450a9a359e74647cc38a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "IntSlider(value=15, description='Epochs', min=1, style=SliderStyle(description_width='initial'))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6561d71fc9b04b189729e376f90b5957",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "FloatSlider(value=0.001, description='Learning Rate:', max=0.999, min=0.001, readout_format='.3f', step=0.001,…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f09940ef98ad4950a0474dc95d880e8d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "IntSlider(value=64, description='Batch Size', max=1024, min=32, step=32, style=SliderStyle(description_width='…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2evpi-TEU3U",
        "outputId": "b7f97fdf-75e7-46d4-cced-767382de16ef"
      },
      "source": [
        "RANDOM_SEED = random_s_in.value\n",
        "EPOCHS = epoch_slider.value\n",
        "LEARNING_RATE = learning_weight.value\n",
        "BATCH_SIZE = batch_slider.value\n",
        "print(RANDOM_SEED, EPOCHS, LEARNING_RATE, BATCH_SIZE)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42 15 0.001 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jo8MdBjiVtCd"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojuEq2H9tivv"
      },
      "source": [
        "Google colab gives us some helpful data in the 'content' directory so we are going to use it for the first \"lessons\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqpqcJOhs7vF"
      },
      "source": [
        "mnist_test = pd.read_csv(\"/content/sample_data/mnist_test.csv\")\n",
        "mnist_train = pd.read_csv(\"/content/sample_data/mnist_train_small.csv\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "y4cjkhnliknS",
        "outputId": "a5cefd48-b725-4290-e055-3a1da9706f22"
      },
      "source": [
        "y_test_ = mnist_test.values[:,0].astype(int)\n",
        "x_test_ = mnist_test.values[:,1:].astype(float)\n",
        "y_train_ = mnist_train.values[:,0].astype(int)\n",
        "x_train_ = mnist_train.values[:,1:].astype(float)\n",
        "\n",
        "np.random.seed(RANDOM_SEED)\n",
        "idx = np.random.randint(0, x_train_.shape[0]) - 9\n",
        "x = plt.title(\"The Number is \"+str(y_train_[idx]))\n",
        "x = plt.imshow(x_train_[idx].reshape((28, 28)), cmap=\"gray\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efrWQZXRkyz2",
        "outputId": "10d44c79-3978-4335-a92d-4832cd48a28d"
      },
      "source": [
        "x_train = torch.tensor(x_train_, dtype=torch.float)\n",
        "y_train = torch.tensor(y_train_, dtype=torch.long)\n",
        "x_test = torch.tensor(x_test_, dtype=torch.float)\n",
        "y_test  = torch.tensor(y_test_, dtype=torch.long)\n",
        "\n",
        "n, c = x_train.shape\n",
        "print(x_train, y_train)\n",
        "print(x_train.shape)\n",
        "print(y_train.min(), y_train.max())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 7, 9,  ..., 2, 9, 5])\n",
            "torch.Size([19999, 784])\n",
            "tensor(0) tensor(9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGITaBbFV8DQ"
      },
      "source": [
        "## Model (\"from scratch\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V_fYoTwrkz6"
      },
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "weights = torch.randn(784, 10) * 0.001\n",
        "weights.requires_grad_()\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "bias = torch.randn(10, requires_grad=True)\n",
        "\n",
        "def log_softmax(x):\n",
        "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
        "\n",
        "def model(xb):\n",
        "    return log_softmax(xb @ weights + bias)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH-Co31QuMj4",
        "outputId": "3dd7775d-b840-4443-8e6f-5d056cd716ff"
      },
      "source": [
        "preds = model(x_train)\n",
        "preds[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3.7377, -3.7460, -1.4511, -4.3113, -7.5470, -1.9996, -4.6817, -4.0796,\n",
              "        -1.7532, -0.9955], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABP8TfNTyDYq",
        "outputId": "bc9e90dc-4511-423a-d463-1149ca0b56a9"
      },
      "source": [
        "def nll(input, target):\n",
        "    return -input[range(target.shape[0]), target].mean()\n",
        "\n",
        "loss_func = nll\n",
        "\n",
        "print(loss_func(preds, y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(4.4897, grad_fn=<NegBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tCEezZ9xVpR",
        "outputId": "f9c941b6-aad3-44e8-bbce-93d873677419"
      },
      "source": [
        "def accuracy(out, yb):\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds == yb).float().mean()\n",
        "\n",
        "acc = accuracy(preds, y_train)\n",
        "print(f\"Accuracy {acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.12800639867782593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOIlBB5HqfEt",
        "outputId": "55b3e184-c068-4bf3-c427-dd3f19f0c262"
      },
      "source": [
        "(weights, bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1.9269e-03,  1.4873e-03,  9.0072e-04,  ..., -1.6047e-03,\n",
              "          -7.5214e-04,  1.6487e-03],\n",
              "         [-3.9248e-04, -1.4036e-03, -7.2788e-04,  ..., -1.5960e-04,\n",
              "          -4.9740e-04,  4.3959e-04],\n",
              "         [-7.5813e-04,  1.0783e-03,  8.0080e-04,  ...,  1.3347e-03,\n",
              "          -2.3162e-04,  4.1759e-05],\n",
              "         ...,\n",
              "         [-5.5956e-05, -4.5470e-04,  1.2942e-03,  ...,  1.1133e-03,\n",
              "           2.1901e-03,  3.5307e-04],\n",
              "         [ 4.4739e-04,  7.1917e-04, -1.9300e-03,  ..., -8.7139e-04,\n",
              "           2.2347e-04,  2.5284e-04],\n",
              "         [ 2.1689e-04,  4.6998e-04,  3.2675e-04,  ...,  4.7023e-05,\n",
              "           5.4871e-04, -1.9951e-03]], requires_grad=True),\n",
              " tensor([ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380,\n",
              "          0.4617,  0.2674], requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDSCFqaVXzjy"
      },
      "source": [
        "preds = model(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU4uT4FlX6-R"
      },
      "source": [
        "loss = loss_func(preds, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xeq1mS_qX8Nt"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrmW7eurYD-W",
        "outputId": "0ffdaf9d-da4d-4d5c-f2f7-5f996bd0daf8"
      },
      "source": [
        "(weights.grad, bias.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
              " tensor([-0.0925, -0.0294, -0.0304, -0.0710, -0.0937, -0.0555,  0.0811, -0.0949,\n",
              "          0.2189,  0.1675]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKCoacT26DRA"
      },
      "source": [
        "with torch.no_grad():\n",
        "  weights -= weights.grad * LEARNING_RATE\n",
        "  bias -= bias.grad * LEARNING_RATE\n",
        "  weights.grad.zero_()\n",
        "  bias.grad.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA8b5POO4q3W",
        "outputId": "fce44812-ef2e-4912-b458-fb79c210cb16"
      },
      "source": [
        "pred = model(x_train)\n",
        "acc1 = accuracy(pred, y_train).item()\n",
        "print(f\"Accuracy before gradient \\\"backprop\\\" {acc}\")\n",
        "print(f\"Accuracy after  gradient \\\"backprop\\\" {acc1}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy before gradient \"backprop\" 0.12800639867782593\n",
            "Accuracy after  gradient \"backprop\" 0.09985499083995819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kz01YNAo7Snz"
      },
      "source": [
        "Well look at that. The accuracy went up!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVewJOqyWJW1"
      },
      "source": [
        "## Baby Pytorch aka applying OOP stuff \n",
        "\n",
        "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fi.kym-cdn.com%2Fentries%2Ficons%2Ffacebook%2F000%2F035%2F094%2FBased_Department_Thumbnail.jpg&f=1&nofb=1\" width=500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkVucZSO7Jax"
      },
      "source": [
        "\n",
        "Introducing nn.Module : https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module  \n",
        "\n",
        "Introducing nn.Parameter : https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter  \n",
        "\n",
        "Introducing nn.functional [loss funcitons](https://pytorch.org/docs/stable/nn.functional.html#cross-entropy) [activation funcitons](https://pytorch.org/docs/stable/nn.functional.html#non-linear-activation-functions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M2FyseV-qGC"
      },
      "source": [
        "loss_func = F.cross_entropy # https://pytorch.org/docs/stable/nn.functional.html#cross-entropy\n",
        "class Mnist_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.weights = nn.Parameter(torch.randn(784, 10) * 0.001)\n",
        "        self.bias = nn.Parameter(torch.randn(10))\n",
        "\n",
        "    def forward(self, xb):\n",
        "        f1 = xb @ self.weights + self.bias\n",
        "        return F.log_softmax(f1, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kO_-bJvh-0yO",
        "outputId": "5ef1f321-8724-4140-acc3-6b2d2dd7528c"
      },
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "model1 = Mnist_model()\n",
        "for p in model1.parameters():\n",
        "  print(p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 1.9269e-03,  1.4873e-03,  9.0072e-04,  ..., -1.6047e-03,\n",
            "         -7.5214e-04,  1.6487e-03],\n",
            "        [-3.9248e-04, -1.4036e-03, -7.2788e-04,  ..., -1.5960e-04,\n",
            "         -4.9740e-04,  4.3959e-04],\n",
            "        [-7.5813e-04,  1.0783e-03,  8.0080e-04,  ...,  1.3347e-03,\n",
            "         -2.3162e-04,  4.1759e-05],\n",
            "        ...,\n",
            "        [-5.5956e-05, -4.5470e-04,  1.2942e-03,  ...,  1.1133e-03,\n",
            "          2.1901e-03,  3.5307e-04],\n",
            "        [ 4.4739e-04,  7.1917e-04, -1.9300e-03,  ..., -8.7139e-04,\n",
            "          2.2347e-04,  2.5284e-04],\n",
            "        [ 2.1689e-04,  4.6998e-04,  3.2675e-04,  ...,  4.7023e-05,\n",
            "          5.4871e-04, -1.9951e-03]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 1.3673, -0.3805,  0.4782,  1.3093,  0.5289,  1.6473,  1.4642,  0.2509,\n",
            "         0.9407,  0.8538], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzLycsUFl7b_",
        "outputId": "2dc1225f-39f1-4e74-8c39-e93e54544a6f"
      },
      "source": [
        "model1(x_train)[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3.5219, -5.0702, -2.0221, -4.0471, -6.7100, -0.9808, -6.2405, -4.0055,\n",
              "        -2.0890, -1.2239], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BmKGI2ulp-T",
        "outputId": "d8a06ea1-b956-4588-ab9a-8ef70af42a4e"
      },
      "source": [
        "print(loss_func(model1(x_train), y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(4.2577, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a315z9UYW8Hv",
        "outputId": "64b3b5c1-6d0d-4e52-c9ae-bff3f397aa3b"
      },
      "source": [
        "preds = model1(x_train)\n",
        "acc2 = accuracy(preds, y_train)\n",
        "print(f\"Accuracy {acc2}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.11885594576597214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7DdejiOcobw"
      },
      "source": [
        "loss = loss_func(model1(x_train), y_train)\n",
        "loss.backward()\n",
        "with torch.no_grad():\n",
        "  for p in model1.parameters():\n",
        "    p -= p.grad * LEARNING_RATE\n",
        "  model1.zero_grad()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIJ_ymhKdA43",
        "outputId": "43c903f9-0b99-4598-e029-450355845038"
      },
      "source": [
        "pred = model(x_train)\n",
        "acc3 = accuracy(pred, y_train).item()\n",
        "print(\"From Scratch\")\n",
        "print(f\"Accuracy before gradient \\\"backprop\\\" {acc}\")\n",
        "print(f\"Accuracy after  gradient \\\"backprop\\\" {acc1}\\n\")\n",
        "print(f\"Model\")\n",
        "print(f\"Accuracy before {acc2}\")\n",
        "print(f\"Accuracy after {acc3}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From Scratch\n",
            "Accuracy before gradient \"backprop\" 0.12800639867782593\n",
            "Accuracy after  gradient \"backprop\" 0.09985499083995819\n",
            "\n",
            "Model\n",
            "Accuracy before 0.11885594576597214\n",
            "Accuracy after 0.09985499083995819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYFSHEFNmwIX"
      },
      "source": [
        "## Baby Pytorch aka applying OOP stuff (Part 2)\n",
        "\n",
        "Introducing nn.Linear : https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear\n",
        "\n",
        "[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) [nn.Parameter](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter) [loss funcitons](https://pytorch.org/docs/stable/nn.functional.html#cross-entropy) [activation funcitons](https://pytorch.org/docs/stable/nn.functional.html#non-linear-activation-functions)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_t1Gnzinphi"
      },
      "source": [
        "loss_func = F.cross_entropy \n",
        "\n",
        "class Mnist_model2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.f1 = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return F.log_softmax(self.f1(xb), dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRRsxuexoLfl",
        "outputId": "2c28ba50-f918-489f-896e-69640ec412c7"
      },
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "model2 = Mnist_model2()\n",
        "model2.f1.bias"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.0093,  0.0283, -0.0033,  0.0255,  0.0017,  0.0037, -0.0302, -0.0123,\n",
              "         0.0018,  0.0163], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8EPRJrBMe25"
      },
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "model2 = Mnist_model2()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guG8DY7Pm5HN",
        "outputId": "802ce7ed-3d4b-4bc6-bfb2-e75aacc3b63b"
      },
      "source": [
        "acc4 = accuracy(model2(x_train), y_train)\n",
        "\n",
        "loss = loss_func(model2(x_train), y_train)\n",
        "loss.backward()\n",
        "with torch.no_grad():\n",
        "  for p in model2.parameters():\n",
        "    p -= p.grad * LEARNING_RATE\n",
        "  model2.zero_grad()\n",
        "acc5 = accuracy(model2(x_train), y_train)\n",
        "\n",
        "print(\"From Scratch\")\n",
        "print(f\"Accuracy before gradient \\\"backprop\\\" {acc}\")\n",
        "print(f\"Accuracy after  gradient \\\"backprop\\\" {acc1}\\n\")\n",
        "print(f\"Model\")\n",
        "print(f\"Accuracy before {acc2}\")\n",
        "print(f\"Accuracy after {acc3}\\n\")\n",
        "print(f\"Model (nn.linear)\")\n",
        "print(f\"Accuracy before {acc4}\")\n",
        "print(f\"Accuracy after {acc5}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From Scratch\n",
            "Accuracy before gradient \"backprop\" 0.12800639867782593\n",
            "Accuracy after  gradient \"backprop\" 0.09985499083995819\n",
            "\n",
            "Model\n",
            "Accuracy before 0.11885594576597214\n",
            "Accuracy after 0.09985499083995819\n",
            "\n",
            "Model (nn.linear)\n",
            "Accuracy before 0.14770738780498505\n",
            "Accuracy after 0.38236913084983826\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pe5D7le0tThX"
      },
      "source": [
        "everyhting is slightly difference this is because of how torch is handling the radnom seeding of all the different "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjYLr4INcpcb"
      },
      "source": [
        "## Pytorch Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v7D4lPOgxdt"
      },
      "source": [
        "class Mnist_model2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.f1 = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return F.log_softmax(self.f1(xb), dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKX1Bnrh_sgk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b3e5cc4-e44e-4dc1-f265-344dca28268d"
      },
      "source": [
        "x_train = torch.tensor(x_train_, dtype=torch.float)\n",
        "y_train = torch.tensor(y_train_, dtype=torch.long)\n",
        "x_test = torch.tensor(x_test_, dtype=torch.float)\n",
        "y_test  = torch.tensor(y_test_, dtype=torch.long)\n",
        "n, c = x_train.shape\n",
        "\n",
        "model3 = Mnist_model2()\n",
        "\n",
        "epoch_loss = {}\n",
        "\n",
        "preds = model3(x_train)\n",
        "acc = accuracy(preds, y_train)\n",
        "print(f\"epoch {-1}/{EPOCHS} - accuracy {acc}\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  epoch_loss[epoch] = []\n",
        "  pred = model3(x_train)\n",
        "  loss = loss_func(pred, y_train)\n",
        "  loss.backward()\n",
        "  epoch_loss[epoch].append(loss.item())\n",
        "  with torch.no_grad():\n",
        "      for p in model3.parameters():\n",
        "          p -= p.grad * LEARNING_RATE\n",
        "      model3.zero_grad()\n",
        "  preds = model3(x_train)\n",
        "  acc = accuracy(preds, y_train)\n",
        "  print(f\"epoch {epoch}/{EPOCHS} - accuracy {acc} - loss {np.array(epoch_loss[epoch]).mean()}\")\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch -1/15 - accuracy 0.053302664309740067\n",
            "epoch 0/15 - accuracy 0.20086003839969635 - loss 79.10369873046875\n",
            "epoch 1/15 - accuracy 0.45312264561653137 - loss 171.3454132080078\n",
            "epoch 2/15 - accuracy 0.28891444206237793 - loss 298.15283203125\n",
            "epoch 3/15 - accuracy 0.47912395000457764 - loss 352.7096862792969\n",
            "epoch 4/15 - accuracy 0.3945697247982025 - loss 327.44842529296875\n",
            "epoch 5/15 - accuracy 0.46417319774627686 - loss 255.85569763183594\n",
            "epoch 6/15 - accuracy 0.5933796763420105 - loss 136.38671875\n",
            "epoch 7/15 - accuracy 0.6091304421424866 - loss 99.59529113769531\n",
            "epoch 8/15 - accuracy 0.6703835129737854 - loss 58.26620101928711\n",
            "epoch 9/15 - accuracy 0.789139449596405 - loss 69.35762786865234\n",
            "epoch 10/15 - accuracy 0.8078904151916504 - loss 17.35070037841797\n",
            "epoch 11/15 - accuracy 0.7762387990951538 - loss 15.038479804992676\n",
            "epoch 12/15 - accuracy 0.7613380551338196 - loss 18.746440887451172\n",
            "epoch 13/15 - accuracy 0.6959847807884216 - loss 26.37175941467285\n",
            "epoch 14/15 - accuracy 0.7259362936019897 - loss 31.45391273498535\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRMzAzjDhGM4"
      },
      "source": [
        "Wait the loss didn't go down and the accuracy is whack.... we are gonna fix this now\n",
        "\n",
        "Why did this happen? [Overfitting](https://www.techopedia.com/definition/32512/overfitting) or [vanishing gradient](https://www.mygreatlearning.com/blog/the-vanishing-gradient-problem/) look below for a quick solution (something which is done anyway)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFRUSwM_hRGN"
      },
      "source": [
        "## Pytorch Training Loop (But with Mini-Batches)\n",
        "\n",
        "---\n",
        "\n",
        "## Batch\n",
        "\n",
        "**Batch gradient** descent is a variation of the gradient descent algorithm that calculates the error for each example in the training dataset, but only updates the model after all training examples have been evaluated.\n",
        "\n",
        "One cycle through the entire training dataset is called a training epoch. Therefore, it is often said that batch gradient descent performs model updates at the end of each training epoch.\n",
        "\n",
        "### Upsides (Batch)\n",
        "\n",
        "*  Fewer updates to the model means this variant of gradient descent is more computationally efficient than stochastic gradient descent.\n",
        "* The decreased update frequency results in a more stable error gradient and may result in a more stable convergence on some problems.\n",
        "* The separation of the calculation of prediction errors and the model update lends the algorithm to parallel processing based implementations.\n",
        "\n",
        "### Downsides (Batch)\n",
        "\n",
        "* The more stable error gradient may result in premature convergence of the model to a less optimal set of parameters.\n",
        "* The updates at the end of the training epoch require the additional complexity of accumulating prediction errors across all training examples.\n",
        "* Commonly, batch gradient descent is implemented in such a way that it requires the entire training dataset in memory and available to the algorithm.\n",
        "* Model updates, and in turn training speed, may become very slow for large datasets.\n",
        "\n",
        "---\n",
        "\n",
        "## Mini-Batch\n",
        "\n",
        "Mini-batch gradient descent is a variation of the gradient descent algorithm that splits the training dataset into small batches that are used to calculate model error and update model coefficients.\n",
        "\n",
        "Implementations may choose to sum the gradient over the mini-batch which further reduces the variance of the gradient.\n",
        "\n",
        "Mini-batch gradient descent seeks to find a balance between the robustness of stochastic gradient descent and the efficiency of batch gradient descent. It is the most common implementation of gradient descent used in the field of deep learning.\n",
        "\n",
        "### Upsides (Mini-Batch)\n",
        "\n",
        "* The model update frequency is higher than batch gradient descent which allows for a more robust convergence, avoiding local minima.\n",
        "* The batched updates provide a computationally more efficient process than stochastic gradient descent.\n",
        "* The batching allows both the efficiency of not having all training data in memory and algorithm implementations.\n",
        "\n",
        "### Downsides (Mini-Batch)\n",
        "* Mini-batch requires the configuration of an additional “mini-batch size” hyperparameter for the learning algorithm.\n",
        "* Error information must be accumulated across mini-batches of training examples like batch gradient descent.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjbZsY9gIGRT"
      },
      "source": [
        "class Mnist_model2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.f1 = nn.Linear(784, 10)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        return F.log_softmax(self.f1(xb), dim=1)\n",
        "  \n",
        "mod = Mnist_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O73y5BcqSCit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b2d686d-eb94-4429-ae6f-499f99f269d3"
      },
      "source": [
        "x_train = torch.tensor(x_train_, dtype=torch.float)\n",
        "y_train = torch.tensor(y_train_, dtype=torch.long)\n",
        "x_test = torch.tensor(x_test_, dtype=torch.float)\n",
        "y_test  = torch.tensor(y_test_, dtype=torch.long)\n",
        "n, c = x_train.shape\n",
        "\n",
        "epoch_loss = {}\n",
        "\n",
        "preds = mod(x_train)\n",
        "acc = accuracy(preds, y_train)\n",
        "print(f\"epoch {-1}/{EPOCHS} - accuracy {acc}\")\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  epoch_loss[epoch] = []\n",
        "  for i in range((n - 1) // BATCH_SIZE + 1): # MINI BATCHES \n",
        "    start_i = i * BATCH_SIZE # MINI BATCHES \n",
        "    end_i = start_i + BATCH_SIZE # MINI BATCHES \n",
        "\n",
        "    xb = x_train[start_i:end_i]\n",
        "    yb = y_train[start_i:end_i]\n",
        "\n",
        "    loss = loss_func(mod(xb), yb)\n",
        "    epoch_loss[epoch].append(loss.item())\n",
        "    loss.backward()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      for p in mod.parameters():\n",
        "        p -= p.grad * LEARNING_RATE\n",
        "      mod.zero_grad()\n",
        "    \n",
        "  acc = accuracy(mod(x_train), y_train)\n",
        "  print(f\"epoch {epoch}/{EPOCHS}\")\n",
        "  print(f\"\\t- accuracy {acc}\")\n",
        "  print(f\"\\t- loss {np.array(epoch_loss[epoch]).mean()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch -1/15 - accuracy 0.09275463968515396\n",
            "epoch 0/15\n",
            "\t- accuracy 0.8144907355308533\n",
            "\t- loss 34.13273558906092\n",
            "epoch 1/15\n",
            "\t- accuracy 0.8567928671836853\n",
            "\t- loss 18.820590083210615\n",
            "epoch 2/15\n",
            "\t- accuracy 0.8566428422927856\n",
            "\t- loss 16.955035898251275\n",
            "epoch 3/15\n",
            "\t- accuracy 0.8736937046051025\n",
            "\t- loss 14.570990884802196\n",
            "epoch 4/15\n",
            "\t- accuracy 0.8299915194511414\n",
            "\t- loss 14.3328085471266\n",
            "epoch 5/15\n",
            "\t- accuracy 0.876943826675415\n",
            "\t- loss 13.835554712496627\n",
            "epoch 6/15\n",
            "\t- accuracy 0.8707935214042664\n",
            "\t- loss 13.821389157789202\n",
            "epoch 7/15\n",
            "\t- accuracy 0.8610430359840393\n",
            "\t- loss 12.561375362233232\n",
            "epoch 8/15\n",
            "\t- accuracy 0.8912445902824402\n",
            "\t- loss 13.496105644935236\n",
            "epoch 9/15\n",
            "\t- accuracy 0.8830441236495972\n",
            "\t- loss 12.594873450315609\n",
            "epoch 10/15\n",
            "\t- accuracy 0.8626431226730347\n",
            "\t- loss 12.393342218269556\n",
            "epoch 11/15\n",
            "\t- accuracy 0.904795229434967\n",
            "\t- loss 12.088932613976086\n",
            "epoch 12/15\n",
            "\t- accuracy 0.8815940618515015\n",
            "\t- loss 12.244654953670198\n",
            "epoch 13/15\n",
            "\t- accuracy 0.8940446972846985\n",
            "\t- loss 12.52809390001975\n",
            "epoch 14/15\n",
            "\t- accuracy 0.8948447704315186\n",
            "\t- loss 11.987669818698407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnFZzFLZnDxW"
      },
      "source": [
        "##  REFACTOR O'CLOCK\n",
        "\n",
        "\n",
        "Introducing Tensor Dataset : https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\n",
        "\n",
        "Introducing Tensor DataLoader : https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset\n",
        "\n",
        "Introducing [optim](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD) [Stochastic Gradient Descent](https://pytorch.org/docs/stable/_modules/torch/optim/sgd.html#SGD)\n",
        "\n",
        "\n",
        "[nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
        "[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) [nn.Parameter](https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html#torch.nn.parameter.Parameter) [loss funcitons](https://pytorch.org/docs/stable/nn.functional.html#cross-entropy) [activation funcitons](https://pytorch.org/docs/stable/nn.functional.html#non-linear-activation-functions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_4uEwqRm3Of"
      },
      "source": [
        "class Mnist_4Layer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.inp = nn.Linear(784, 64)\n",
        "        self.out = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, xb):\n",
        "        feed = self.out(self.inp(xb))\n",
        "        return F.log_softmax(feed, dim=1)\n",
        "  \n",
        "model4 = Mnist_4Layer() \n",
        "opt = torch.optim.SGD(model4.parameters(), lr=LEARNING_RATE) # OPTIMIZER TIME\n",
        "\n",
        "x_train = torch.tensor(x_train_, dtype=torch.float)\n",
        "y_train = torch.tensor(y_train_, dtype=torch.long)\n",
        "x_test = torch.tensor(x_test_, dtype=torch.float)\n",
        "y_test  = torch.tensor(y_test_, dtype=torch.long)\n",
        "\n",
        "n, c = x_train.shape\n",
        "\n",
        "train_ds = TensorDataset(x_train, y_train) # Put data in a dataset\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE) # Put dataset in a dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrTBWY39m4Le",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb2d8081-8b84-4d27-99d9-847fc77d4e4f"
      },
      "source": [
        "total_parameters = 0\n",
        "for p in model4.parameters():\n",
        "  total_parameters += np.prod(p.size())\n",
        "total_parameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50890"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx1g7TzAhEyX",
        "outputId": "e056a192-2088-4199-ff52-daca149d0308"
      },
      "source": [
        "epoch_loss = {}\n",
        "for epoch in range(EPOCHS):\n",
        "  epoch_loss[epoch]= []\n",
        "  for xb, yb in train_dl:\n",
        "    loss = loss_func(model4(xb), yb)\n",
        "    epoch_loss[epoch].append(loss.item())\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "  acc = accuracy(model4(x_train), y_train)\n",
        "  print(f\"epoch {epoch+1}/{EPOCHS}\")\n",
        "  print(f\"\\t- accuracy {acc}\")\n",
        "  print(f\"\\t- loss {np.array(epoch_loss[epoch]).mean()}\")\n",
        "t_acc = accuracy(model4(x_test), y_test)\n",
        "print(f\"Test accuracy {t_acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1/15\n",
            "\t- accuracy 0.8721436262130737\n",
            "\t- loss 6.847581973471962\n",
            "epoch 2/15\n",
            "\t- accuracy 0.8840442299842834\n",
            "\t- loss 0.8659012737794044\n",
            "epoch 3/15\n",
            "\t- accuracy 0.8716936111450195\n",
            "\t- loss 0.5457172826075325\n",
            "epoch 4/15\n",
            "\t- accuracy 0.8848942518234253\n",
            "\t- loss 0.43755984432495443\n",
            "epoch 5/15\n",
            "\t- accuracy 0.8938946723937988\n",
            "\t- loss 0.387576367122868\n",
            "epoch 6/15\n",
            "\t- accuracy 0.9010950326919556\n",
            "\t- loss 0.36045452554861956\n",
            "epoch 7/15\n",
            "\t- accuracy 0.9061952829360962\n",
            "\t- loss 0.34399788105449736\n",
            "epoch 8/15\n",
            "\t- accuracy 0.9094454646110535\n",
            "\t- loss 0.3327209719310934\n",
            "epoch 9/15\n",
            "\t- accuracy 0.9118955731391907\n",
            "\t- loss 0.32421821922349475\n",
            "epoch 10/15\n",
            "\t- accuracy 0.9136456847190857\n",
            "\t- loss 0.31743103608536644\n",
            "epoch 11/15\n",
            "\t- accuracy 0.9145457148551941\n",
            "\t- loss 0.3117841675687141\n",
            "epoch 12/15\n",
            "\t- accuracy 0.9164458513259888\n",
            "\t- loss 0.30692936887089817\n",
            "epoch 13/15\n",
            "\t- accuracy 0.9176458716392517\n",
            "\t- loss 0.3026497086492209\n",
            "epoch 14/15\n",
            "\t- accuracy 0.9185459017753601\n",
            "\t- loss 0.29880631619844195\n",
            "epoch 15/15\n",
            "\t- accuracy 0.9202960133552551\n",
            "\t- loss 0.2953072189570616\n",
            "Test accuracy 0.9016901850700378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDlbD7RyKTVQ"
      },
      "source": [
        "Well finally look at that! accuracy go up loss go down! its basically learning!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Sv9WR7BKPoe"
      },
      "source": [
        "<img src=\"https://i.redd.it/nc5ua4x8lfg31.png\" width=500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kpma3koM4HW"
      },
      "source": [
        "## Refactor 2 Electric Boogaloo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXVSfUQjKcvM",
        "outputId": "8580846a-4dc3-49b1-af51-44f9daa171eb"
      },
      "source": [
        "x_train = torch.tensor(x_train_, dtype=torch.float)\n",
        "y_train = torch.tensor(y_train_, dtype=torch.long)\n",
        "x_test = torch.tensor(x_test_, dtype=torch.float)\n",
        "y_test  = torch.tensor(y_test_, dtype=torch.long)\n",
        "n, c = x_train.shape\n",
        "\n",
        "train_ds = TensorDataset(x_train, y_train)\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_ds = TensorDataset(x_test, y_test)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=BATCH_SIZE * 2)\n",
        "\n",
        "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
        "  loss = loss_func(model(xb), yb)\n",
        "  if opt is not None:\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "  return loss.item(), len(xb)\n",
        "\n",
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "  history = []\n",
        "  for epoch in range(epochs):\n",
        "    t1 = int(time.time() * 1000) \n",
        "    model.train()\n",
        "    for xb, yb in train_dl:\n",
        "      loss_batch(model, loss_func, xb, yb, opt)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      losses, nums = zip(\n",
        "        *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
        "      )\n",
        "    val_acc = np.array([accuracy(model(xb), yb).item() for xb, yb in valid_dl]).mean()\n",
        "    val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
        "    t_ex = round((int(time.time() * 1000) ) - t1, 0)\n",
        "    history.append({\n",
        "        \"epoch\": epoch,\n",
        "        \"val_acc\": val_acc,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"time\": t_ex\n",
        "    })\n",
        "    print(f\"Epoch: {epoch+1}\\tVal. Loss: {val_loss}\\tVal. Acc. {val_acc}\\tTime {t_ex}ms\")\n",
        "  return history\n",
        "\n",
        "model4 = Mnist_4Layer() \n",
        "opt = torch.optim.SGD(model4.parameters(), lr=LEARNING_RATE)\n",
        "history1 = fit(EPOCHS, model4, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\tVal. Loss: 1.0691179812553584\tVal. Acc. 0.8925501055355314\tTime 923ms\n",
            "Epoch: 2\tVal. Loss: 0.751519966286735\tVal. Acc. 0.8792985232570504\tTime 811ms\n",
            "Epoch: 3\tVal. Loss: 0.5220511012812807\tVal. Acc. 0.8767273207254047\tTime 802ms\n",
            "Epoch: 4\tVal. Loss: 0.47603546651360606\tVal. Acc. 0.8844409283203415\tTime 799ms\n",
            "Epoch: 5\tVal. Loss: 0.4125236350365288\tVal. Acc. 0.8954179852823668\tTime 811ms\n",
            "Epoch: 6\tVal. Loss: 0.48746596212827725\tVal. Acc. 0.874202268033088\tTime 818ms\n",
            "Epoch: 7\tVal. Loss: 0.4199807307299095\tVal. Acc. 0.8943301688266706\tTime 809ms\n",
            "Epoch: 8\tVal. Loss: 0.37446385597956755\tVal. Acc. 0.9012064873417721\tTime 816ms\n",
            "Epoch: 9\tVal. Loss: 0.4479860054879132\tVal. Acc. 0.883946466295025\tTime 797ms\n",
            "Epoch: 10\tVal. Loss: 0.435896041374145\tVal. Acc. 0.8743539030038858\tTime 806ms\n",
            "Epoch: 11\tVal. Loss: 0.46860426840501757\tVal. Acc. 0.858577268033088\tTime 812ms\n",
            "Epoch: 12\tVal. Loss: 0.3647937056991217\tVal. Acc. 0.9040216245228732\tTime 809ms\n",
            "Epoch: 13\tVal. Loss: 0.4274174020920817\tVal. Acc. 0.8863726265822784\tTime 812ms\n",
            "Epoch: 14\tVal. Loss: 0.3746511856302081\tVal. Acc. 0.900955959965911\tTime 815ms\n",
            "Epoch: 15\tVal. Loss: 0.3939586373368124\tVal. Acc. 0.8984836498393288\tTime 818ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwStEPDPGMSw"
      },
      "source": [
        "<img src=\"https://media1.tenor.com/images/2bf30b6dfae9bd44be613a13deb6b52b/tenor.gif?itemid=12466201\" alt=\"yeeeeee boi\"  width=250/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFmDcfCjOXvP"
      },
      "source": [
        "## CNN Time\n",
        "\n",
        "Understanding CNN'a  \n",
        "https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148\n",
        "\n",
        "Understanding nn.sequential   \n",
        "https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential\n",
        "\n",
        "\n",
        "Understanding nn.ReLU   \n",
        "https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU\n",
        "\n",
        "\n",
        "Understanding nn.Conv2D. \n",
        "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d\n",
        "\n",
        "\n",
        "Understanding nn.AdaptiveAvgPool2d https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html#torch.nn.AdaptiveAvgPool2d\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOQG-jW6OHsk",
        "outputId": "7be829dd-dc29-41de-a11b-f8a38c04eb6f"
      },
      "source": [
        "class Mnist_CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
        "    self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
        "    self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "  def forward(self, xb):\n",
        "    xb = xb.view(-1, 1, 28, 28)\n",
        "    xb = F.relu(self.conv1(xb))\n",
        "    xb = F.relu(self.conv2(xb))\n",
        "    xb = F.relu(self.conv3(xb))\n",
        "    xb = F.avg_pool2d(xb, 4)\n",
        "    return xb.view(-1, xb.size(1))\n",
        "\n",
        "model = Mnist_CNN()\n",
        "opt = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "\n",
        "cnnhist1 = fit(EPOCHS, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\tVal. Loss: 0.7380812551208896\tVal. Acc. 0.7755010550535177\tTime 2845ms\n",
            "Epoch: 2\tVal. Loss: 0.4378509386153397\tVal. Acc. 0.8667919303797469\tTime 2606ms\n",
            "Epoch: 3\tVal. Loss: 0.38099670012329967\tVal. Acc. 0.888943829113924\tTime 2612ms\n",
            "Epoch: 4\tVal. Loss: 0.32389138697242603\tVal. Acc. 0.9056566455696202\tTime 2607ms\n",
            "Epoch: 5\tVal. Loss: 0.2964937323016046\tVal. Acc. 0.9156447784810127\tTime 2582ms\n",
            "Epoch: 6\tVal. Loss: 0.2682846642297433\tVal. Acc. 0.9222705696202531\tTime 2640ms\n",
            "Epoch: 7\tVal. Loss: 0.2433476589146209\tVal. Acc. 0.9292919303797469\tTime 2590ms\n",
            "Epoch: 8\tVal. Loss: 0.23189513797596348\tVal. Acc. 0.9329509493670886\tTime 2633ms\n",
            "Epoch: 9\tVal. Loss: 0.22838670839349254\tVal. Acc. 0.9324564873417721\tTime 2599ms\n",
            "Epoch: 10\tVal. Loss: 0.23267159216131644\tVal. Acc. 0.9308742088607594\tTime 2638ms\n",
            "Epoch: 11\tVal. Loss: 0.24616178944863396\tVal. Acc. 0.9281052215189873\tTime 2638ms\n",
            "Epoch: 12\tVal. Loss: 0.23290714428209924\tVal. Acc. 0.9294897151898734\tTime 2655ms\n",
            "Epoch: 13\tVal. Loss: 0.2179916676378647\tVal. Acc. 0.934434335443038\tTime 2639ms\n",
            "Epoch: 14\tVal. Loss: 0.1977682148458192\tVal. Acc. 0.9414556962025317\tTime 2626ms\n",
            "Epoch: 15\tVal. Loss: 0.19351259159623344\tVal. Acc. 0.9409612341772152\tTime 2624ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXio8whpQfam"
      },
      "source": [
        "Let’s get rid of these two assumptions, so our model works with any 2d single channel image. First, we can remove the initial Lambda layer but moving the data preprocessing into a generator\n",
        "\n",
        "\n",
        "\n",
        "Next, we can replace nn.AvgPool2d with nn.AdaptiveAvgPool2d, which allows us to define the size of the output tensor we want, rather than the input tensor we have. As a result, our model will work with any size input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "xs5lDShHOqfM",
        "outputId": "f0f972bd-4afb-4b5d-9734-ac7cc74e515b"
      },
      "source": [
        "def get_data(train_ds, valid_ds, bs):\n",
        "    return (\n",
        "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
        "        DataLoader(valid_ds, batch_size=bs * 2),\n",
        "    )\n",
        "\n",
        "class Lambda(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super().__init__()\n",
        "        self.func = func\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.func(x)\n",
        "\n",
        "def preprocess(x, y):\n",
        "    return x.view(-1, 1, 28, 28), y\n",
        "\n",
        "\n",
        "class WrappedDataLoader:\n",
        "    def __init__(self, dl, func):\n",
        "        self.dl = dl\n",
        "        self.func = func\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dl)\n",
        "\n",
        "    def __iter__(self):\n",
        "        batches = iter(self.dl)\n",
        "        for b in batches:\n",
        "            yield (self.func(*b))\n",
        "\n",
        "train_dl, valid_dl = get_data(train_ds, valid_ds, BATCH_SIZE)\n",
        "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
        "valid_dl = WrappedDataLoader(valid_dl, preprocess)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.AdaptiveAvgPool2d(1),\n",
        "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
        ")\n",
        "\n",
        "opt = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "\n",
        "cnnhist2 = fit(EPOCHS, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\tVal. Loss: 1.2720006254866476\tVal. Acc. 0.6001120783105681\tTime 2652ms\n",
            "Epoch: 2\tVal. Loss: 1.0538338959747606\tVal. Acc. 0.6907898210272004\tTime 2627ms\n",
            "Epoch: 3\tVal. Loss: 0.8009540504462147\tVal. Acc. 0.7695675107497203\tTime 2621ms\n",
            "Epoch: 4\tVal. Loss: 0.7923366118400189\tVal. Acc. 0.7669963082180747\tTime 2613ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-f09c575ac1ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mcnnhist2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-39-12448187d24a>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, train_dl, valid_dl)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m       \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-12448187d24a>\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, loss_func, xb, yb, opt)\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpchjQTdV2VN"
      },
      "source": [
        "We promised at the start of this tutorial we’d explain through example each of torch.nn, torch.optim, Dataset, and DataLoader. So let’s summarize what we’ve seen:\n",
        "\n",
        "**torch.nn**\n",
        "\n",
        "* Module: creates a callable which behaves like a function, but can also contain state(such as neural net layer weights). It knows what Parameter (s) it contains and can zero all their gradients, loop through them for weight updates, etc.\n",
        "\n",
        "* Parameter: a wrapper for a tensor that tells a Module that it has weights that need updating during backprop. Only tensors with the requires_grad attribute set are updated\n",
        "\n",
        "* functional: a module(usually imported into the F namespace by convention) which contains activation functions, loss functions, etc, as well as non-stateful versions of layers such as convolutional and linear layers.\n",
        "\n",
        "* torch.optim: Contains optimizers such as SGD, which update the weights of Parameter during the backward step\n",
        "\n",
        "* Dataset: An abstract interface of objects with a __len__ and a __getitem__, including classes provided with Pytorch such as TensorDataset\n",
        "\n",
        "* DataLoader: Takes any Dataset and creates an iterator which returns batches of data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wvNxAeJUPJD"
      },
      "source": [
        "## LETS GET GPUS INVOLVED\n",
        "\n",
        "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Flinustechtips.com%2Fmain%2Fuploads%2Fmonthly_09_2015%2Fpost-253099-0-17139900-1441340727.jpg&f=1&nofb=1\" width=500 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCQQNnDeUjej"
      },
      "source": [
        "Runtime > Change Runtime Type > Hardware accelerator - choose GPU\n",
        "\n",
        "Once the session reloads you can just rerun setup and data until here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YOM5UM0T-Mc",
        "outputId": "f2b96dd7-7911-43e1-f5b5-75a16aaf37d3"
      },
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTp3KRwcU--K"
      },
      "source": [
        "ayyy theres a GPU here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1chFhxWT7zk"
      },
      "source": [
        "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwGX2-JPiBrb"
      },
      "source": [
        "def accuracy(out, yb):\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds == yb).float().mean()\n",
        "\n",
        "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
        "  loss = loss_func(model(xb), yb)\n",
        "  if opt is not None:\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    opt.zero_grad()\n",
        "  return loss.item(), len(xb)\n",
        "\n",
        "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
        "  history = []\n",
        "  for epoch in range(epochs):\n",
        "    t1 = int(time.time() * 1000) \n",
        "    model.train()\n",
        "    for xb, yb in train_dl:\n",
        "      loss_batch(model, loss_func, xb, yb, opt)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      losses, nums = zip(\n",
        "        *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl]\n",
        "      )\n",
        "    val_acc = np.array([accuracy(model(xb), yb).item() for xb, yb in valid_dl]).mean()\n",
        "    val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
        "    t_ex = round((int(time.time() * 1000) ) - t1, 0)\n",
        "    history.append({\n",
        "        \"epoch\": epoch,\n",
        "        \"val_acc\": val_acc,\n",
        "        \"val_loss\": val_loss,\n",
        "        \"time\": t_ex\n",
        "    })\n",
        "    print(f\"Epoch: {epoch+1}\\tVal. Loss: {val_loss}\\tVal. Acc. {val_acc}\\tTime {t_ex}ms\")\n",
        "  return history\n",
        "\n",
        "def get_data(train_ds, valid_ds, bs):\n",
        "    return (\n",
        "        DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
        "        DataLoader(valid_ds, batch_size=bs * 2),\n",
        "    )\n",
        "\n",
        "class Lambda(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super().__init__()\n",
        "        self.func = func\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.func(x)\n",
        "\n",
        "def preprocess_nogpu(x, y):\n",
        "    return x.view(-1, 1, 28, 28), y\n",
        "\n",
        "def preprocess(x, y):\n",
        "    return x.view(-1, 1, 28, 28).to(dev), y.to(dev)\n",
        "\n",
        "\n",
        "class WrappedDataLoader:\n",
        "    def __init__(self, dl, func):\n",
        "        self.dl = dl\n",
        "        self.func = func\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dl)\n",
        "\n",
        "    def __iter__(self):\n",
        "        batches = iter(self.dl)\n",
        "        for b in batches:\n",
        "            yield (self.func(*b))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8we-FB5T8P1",
        "outputId": "e28020b3-b4a9-4afe-a370-15ec58770efb"
      },
      "source": [
        "loss_func = F.cross_entropy \n",
        "\n",
        "train_ds = TensorDataset(x_train, y_train)\n",
        "valid_ds = TensorDataset(x_test, y_test)\n",
        "train_dl, valid_dl = get_data(train_ds, valid_ds, BATCH_SIZE)\n",
        "train_dl = WrappedDataLoader(train_dl, preprocess)\n",
        "valid_dl = WrappedDataLoader(valid_dl, preprocess)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(),\n",
        "    nn.AdaptiveAvgPool2d(1),\n",
        "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
        ")\n",
        "\n",
        "model.to(dev)\n",
        "opt = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "\n",
        "cnnhistgpu = fit(EPOCHS, model, loss_func, opt, train_dl, valid_dl)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\tVal. Loss: 0.5991596102130354\tVal. Acc. 0.8206553278090079\tTime 1296ms\n",
            "Epoch: 2\tVal. Loss: 0.4377286419107003\tVal. Acc. 0.8676819620253164\tTime 1125ms\n",
            "Epoch: 3\tVal. Loss: 0.33747692095010157\tVal. Acc. 0.8920556442647041\tTime 1131ms\n",
            "Epoch: 4\tVal. Loss: 0.286717852297211\tVal. Acc. 0.9142602848101266\tTime 1127ms\n",
            "Epoch: 5\tVal. Loss: 0.3743797455302285\tVal. Acc. 0.8760284819180453\tTime 1147ms\n",
            "Epoch: 6\tVal. Loss: 0.27155797938630993\tVal. Acc. 0.9222705696202531\tTime 1130ms\n",
            "Epoch: 7\tVal. Loss: 0.3029369989724675\tVal. Acc. 0.9104034810126582\tTime 1135ms\n",
            "Epoch: 8\tVal. Loss: 0.22895505493677237\tVal. Acc. 0.9330498417721519\tTime 1155ms\n",
            "Epoch: 9\tVal. Loss: 0.25535162557812496\tVal. Acc. 0.9204905063291139\tTime 1129ms\n",
            "Epoch: 10\tVal. Loss: 0.21950690642428441\tVal. Acc. 0.9357199367088608\tTime 1115ms\n",
            "Epoch: 11\tVal. Loss: 0.23957874785081568\tVal. Acc. 0.9256329113924051\tTime 1114ms\n",
            "Epoch: 12\tVal. Loss: 0.20630458665575602\tVal. Acc. 0.9402689873417721\tTime 1125ms\n",
            "Epoch: 13\tVal. Loss: 0.19072591053760282\tVal. Acc. 0.943631329113924\tTime 1122ms\n",
            "Epoch: 14\tVal. Loss: 0.18882447510942071\tVal. Acc. 0.9454113924050633\tTime 1141ms\n",
            "Epoch: 15\tVal. Loss: 0.21810098392146565\tVal. Acc. 0.9319620253164557\tTime 1131ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFqaTj1QpoJo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "d2f68592-fd64-426d-e601-703a046edb49"
      },
      "source": [
        "avg_time_nogpu = np.array([x[\"time\"] for x in cnnhist2]).mean()\n",
        "print(f\"CNN model avg epoch time (no GPU) = {avg_time_nogpu}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-eaa9a9d493c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mavg_time_nogpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"time\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcnnhist2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"CNN model avg epoch time (no GPU) = {avg_time_nogpu}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cnnhist2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf9UZGgHVUsJ",
        "outputId": "469630a4-6fcf-417b-86a7-0bad3948be6c"
      },
      "source": [
        "avg_time_gpu = np.array([x[\"time\"] for x in cnnhistgpu]).mean()\n",
        "print(f\"CNN model avg epoch time (GPU) = {avg_time_gpu}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN model avg epoch time (GPU) = 1141.5333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjVuHwbwzbgX"
      },
      "source": [
        "## Aside - Visualize the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVCsAOpnGram"
      },
      "source": [
        "train_dl, valid_dl = get_data(train_ds, valid_ds, BATCH_SIZE)\n",
        "valid_dl = WrappedDataLoader(valid_dl, preprocess_nogpu)\n",
        "model.to('cpu')\n",
        "inputs, classes = next(iter(valid_dl))\n",
        "y = model(inputs)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "QlbonKynHFSZ",
        "outputId": "17735c09-ceef-48c9-f532-0379352c93e7"
      },
      "source": [
        "hl.build_graph(model, torch.zeros([16, 1, 3, 3]))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<hiddenlayer.graph.Graph at 0x7f5405fa1080>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"817pt\" height=\"190pt\"\n viewBox=\"0.00 0.00 817.00 190.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(72 154)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-72,36 -72,-154 745,-154 745,36 -72,36\"/>\n<!-- /outputs/13 -->\n<g id=\"node1\" class=\"node\">\n<title>/outputs/13</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"216,-41 120,-41 120,-5 216,-5 216,-41\"/>\n<text text-anchor=\"start\" x=\"128\" y=\"-20\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">GlobalAveragePool</text>\n</g>\n<!-- /outputs/14 -->\n<g id=\"node2\" class=\"node\">\n<title>/outputs/14</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"306,-64 252,-64 252,-28 306,-28 306,-64\"/>\n<text text-anchor=\"start\" x=\"267\" y=\"-43\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Shape</text>\n</g>\n<!-- /outputs/13&#45;&gt;/outputs/14 -->\n<g id=\"edge1\" class=\"edge\">\n<title>/outputs/13&#45;&gt;/outputs/14</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M216.0406,-32.9544C224.7882,-34.7669 233.7876,-36.6317 242.1481,-38.364\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"241.4673,-41.7972 251.9694,-40.3991 242.8876,-34.9428 241.4673,-41.7972\"/>\n</g>\n<!-- /outputs/21 -->\n<g id=\"node9\" class=\"node\">\n<title>/outputs/21</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"673,-41 619,-41 619,-5 673,-5 673,-41\"/>\n<text text-anchor=\"start\" x=\"629\" y=\"-20\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Reshape</text>\n</g>\n<!-- /outputs/13&#45;&gt;/outputs/21 -->\n<g id=\"edge2\" class=\"edge\">\n<title>/outputs/13&#45;&gt;/outputs/21</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M216.1534,-14.3702C256.7617,-7.8439 316.4903,0 369,0 369,0 369,0 462.5,0 513.3468,0 571.5079,-8.8019 608.475,-15.5157\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"608.3038,-19.0438 618.7753,-17.4323 609.5844,-12.162 608.3038,-19.0438\"/>\n</g>\n<!-- /outputs/16 -->\n<g id=\"node4\" class=\"node\">\n<title>/outputs/16</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"396,-64 342,-64 342,-28 396,-28 396,-64\"/>\n<text text-anchor=\"start\" x=\"355\" y=\"-43\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Gather</text>\n</g>\n<!-- /outputs/14&#45;&gt;/outputs/16 -->\n<g id=\"edge3\" class=\"edge\">\n<title>/outputs/14&#45;&gt;/outputs/16</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M306.003,-46C314.0277,-46 322.9665,-46 331.5309,-46\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"331.7051,-49.5001 341.705,-46 331.705,-42.5001 331.7051,-49.5001\"/>\n</g>\n<!-- /outputs/15 -->\n<g id=\"node3\" class=\"node\">\n<title>/outputs/15</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"306,-118 252,-118 252,-82 306,-82 306,-118\"/>\n<text text-anchor=\"start\" x=\"261\" y=\"-97\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n</g>\n<!-- /outputs/15&#45;&gt;/outputs/16 -->\n<g id=\"edge4\" class=\"edge\">\n<title>/outputs/15&#45;&gt;/outputs/16</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M306.003,-83.7982C314.4686,-78.7188 323.9516,-73.029 332.9389,-67.6366\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"334.9308,-70.5232 341.705,-62.377 331.3293,-64.5208 334.9308,-70.5232\"/>\n</g>\n<!-- /outputs/18 -->\n<g id=\"node6\" class=\"node\">\n<title>/outputs/18</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"493,-64 432,-64 432,-28 493,-28 493,-64\"/>\n<text text-anchor=\"start\" x=\"440.5\" y=\"-43\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\n</g>\n<!-- /outputs/16&#45;&gt;/outputs/18 -->\n<g id=\"edge5\" class=\"edge\">\n<title>/outputs/16&#45;&gt;/outputs/18</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M396.0441,-46C404.1072,-46 413.1275,-46 421.8587,-46\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"421.9008,-49.5001 431.9008,-46 421.9007,-42.5001 421.9008,-49.5001\"/>\n</g>\n<!-- /outputs/17 -->\n<g id=\"node5\" class=\"node\">\n<title>/outputs/17</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"396,-118 342,-118 342,-82 396,-82 396,-118\"/>\n<text text-anchor=\"start\" x=\"351\" y=\"-97\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Constant</text>\n</g>\n<!-- /outputs/19 -->\n<g id=\"node7\" class=\"node\">\n<title>/outputs/19</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"493,-118 432,-118 432,-82 493,-82 493,-118\"/>\n<text text-anchor=\"start\" x=\"440.5\" y=\"-97\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Unsqueeze</text>\n</g>\n<!-- /outputs/17&#45;&gt;/outputs/19 -->\n<g id=\"edge6\" class=\"edge\">\n<title>/outputs/17&#45;&gt;/outputs/19</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M396.0441,-100C404.1072,-100 413.1275,-100 421.8587,-100\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"421.9008,-103.5001 431.9008,-100 421.9007,-96.5001 421.9008,-103.5001\"/>\n</g>\n<!-- /outputs/20 -->\n<g id=\"node8\" class=\"node\">\n<title>/outputs/20</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"583,-64 529,-64 529,-28 583,-28 583,-64\"/>\n<text text-anchor=\"start\" x=\"541\" y=\"-43\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Concat</text>\n</g>\n<!-- /outputs/18&#45;&gt;/outputs/20 -->\n<g id=\"edge7\" class=\"edge\">\n<title>/outputs/18&#45;&gt;/outputs/20</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M493.1154,-46C501.294,-46 510.2234,-46 518.7177,-46\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"518.7832,-49.5001 528.7832,-46 518.7832,-42.5001 518.7832,-49.5001\"/>\n</g>\n<!-- /outputs/19&#45;&gt;/outputs/20 -->\n<g id=\"edge8\" class=\"edge\">\n<title>/outputs/19&#45;&gt;/outputs/20</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M493.1154,-82.3184C501.7433,-77.3354 511.207,-71.8698 520.1137,-66.7258\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"521.8741,-69.7509 528.7832,-61.7188 518.3732,-63.6892 521.8741,-69.7509\"/>\n</g>\n<!-- /outputs/20&#45;&gt;/outputs/21 -->\n<g id=\"edge9\" class=\"edge\">\n<title>/outputs/20&#45;&gt;/outputs/21</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M583.003,-39.0992C591.1158,-37.0259 600.1631,-34.7139 608.8131,-32.5033\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"609.883,-35.8425 618.705,-29.9754 608.1498,-29.0604 609.883,-35.8425\"/>\n</g>\n<!-- 12025253292687699098 -->\n<g id=\"node10\" class=\"node\">\n<title>12025253292687699098</title>\n<polygon fill=\"#e8e8e8\" stroke=\"#000000\" points=\"84,-45 0,-45 0,-1 84,-1 84,-45\"/>\n<text text-anchor=\"start\" x=\"8\" y=\"-29\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">Conv3x3 &gt; Relu</text>\n<text text-anchor=\"start\" x=\"69\" y=\"-8\" font-family=\"Times\" font-size=\"10.00\" fill=\"#000000\">x3</text>\n</g>\n<!-- 12025253292687699098&#45;&gt;/outputs/13 -->\n<g id=\"edge10\" class=\"edge\">\n<title>12025253292687699098&#45;&gt;/outputs/13</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M84.3067,-23C92.5284,-23 101.279,-23 109.9062,-23\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"109.938,-26.5001 119.9379,-23 109.9379,-19.5001 109.938,-26.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "zcvtdLeZyxqk",
        "outputId": "d41127aa-3c37-4086-e483-2cf42b761f60"
      },
      "source": [
        "make_dot(y, params=dict(model.named_parameters()))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f540b6e0e80>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"414pt\" height=\"524pt\"\n viewBox=\"0.00 0.00 414.00 524.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 520)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-520 410,-520 410,4 -4,4\"/>\n<!-- 139998945739496 -->\n<g id=\"node1\" class=\"node\">\n<title>139998945739496</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"338.5,-21 247.5,-21 247.5,0 338.5,0 338.5,-21\"/>\n<text text-anchor=\"middle\" x=\"293\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ViewBackward</text>\n</g>\n<!-- 139998945739664 -->\n<g id=\"node2\" class=\"node\">\n<title>139998945739664</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"342,-78 244,-78 244,-57 342,-57 342,-78\"/>\n<text text-anchor=\"middle\" x=\"293\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MeanBackward1</text>\n</g>\n<!-- 139998945739664&#45;&gt;139998945739496 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139998945739664&#45;&gt;139998945739496</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M293,-56.7787C293,-49.6134 293,-39.9517 293,-31.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"296.5001,-31.1732 293,-21.1732 289.5001,-31.1732 296.5001,-31.1732\"/>\n</g>\n<!-- 139998945742688 -->\n<g id=\"node3\" class=\"node\">\n<title>139998945742688</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"340,-135 246,-135 246,-114 340,-114 340,-135\"/>\n<text text-anchor=\"middle\" x=\"293\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 139998945742688&#45;&gt;139998945739664 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139998945742688&#45;&gt;139998945739664</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M293,-113.7787C293,-106.6134 293,-96.9517 293,-88.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"296.5001,-88.1732 293,-78.1732 289.5001,-88.1732 296.5001,-88.1732\"/>\n</g>\n<!-- 139998945740280 -->\n<g id=\"node4\" class=\"node\">\n<title>139998945740280</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"374,-192 212,-192 212,-171 374,-171 374,-192\"/>\n<text text-anchor=\"middle\" x=\"293\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139998945740280&#45;&gt;139998945742688 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139998945740280&#45;&gt;139998945742688</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M293,-170.7787C293,-163.6134 293,-153.9517 293,-145.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"296.5001,-145.1732 293,-135.1732 289.5001,-145.1732 296.5001,-145.1732\"/>\n</g>\n<!-- 139998945740056 -->\n<g id=\"node5\" class=\"node\">\n<title>139998945740056</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"234,-255.5 140,-255.5 140,-234.5 234,-234.5 234,-255.5\"/>\n<text text-anchor=\"middle\" x=\"187\" y=\"-241.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 139998945740056&#45;&gt;139998945740280 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139998945740056&#45;&gt;139998945740280</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M204.9815,-234.2281C221.9106,-224.0866 247.4677,-208.7764 266.6884,-197.2622\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"268.5043,-200.2544 275.2841,-192.1128 264.9069,-194.2494 268.5043,-200.2544\"/>\n</g>\n<!-- 139998945739272 -->\n<g id=\"node6\" class=\"node\">\n<title>139998945739272</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"268,-319 106,-319 106,-298 268,-298 268,-319\"/>\n<text text-anchor=\"middle\" x=\"187\" y=\"-305.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139998945739272&#45;&gt;139998945740056 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139998945739272&#45;&gt;139998945740056</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M187,-297.7281C187,-289.0091 187,-276.4699 187,-265.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.5001,-265.6128 187,-255.6128 183.5001,-265.6129 190.5001,-265.6128\"/>\n</g>\n<!-- 139999076734232 -->\n<g id=\"node7\" class=\"node\">\n<title>139999076734232</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"128,-382.5 34,-382.5 34,-361.5 128,-361.5 128,-382.5\"/>\n<text text-anchor=\"middle\" x=\"81\" y=\"-368.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 139999076734232&#45;&gt;139998945739272 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139999076734232&#45;&gt;139998945739272</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M98.9815,-361.2281C115.9106,-351.0866 141.4677,-335.7764 160.6884,-324.2622\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"162.5043,-327.2544 169.2841,-319.1128 158.9069,-321.2494 162.5043,-327.2544\"/>\n</g>\n<!-- 139999076734400 -->\n<g id=\"node8\" class=\"node\">\n<title>139999076734400</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"162,-446 0,-446 0,-425 162,-425 162,-446\"/>\n<text text-anchor=\"middle\" x=\"81\" y=\"-432.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MkldnnConvolutionBackward</text>\n</g>\n<!-- 139999076734400&#45;&gt;139999076734232 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139999076734400&#45;&gt;139999076734232</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M81,-424.7281C81,-416.0091 81,-403.4699 81,-392.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"84.5001,-392.6128 81,-382.6128 77.5001,-392.6129 84.5001,-392.6128\"/>\n</g>\n<!-- 139999076736360 -->\n<g id=\"node9\" class=\"node\">\n<title>139999076736360</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"77.5,-516 2.5,-516 2.5,-482 77.5,-482 77.5,-516\"/>\n<text text-anchor=\"middle\" x=\"40\" y=\"-502.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">0.weight</text>\n<text text-anchor=\"middle\" x=\"40\" y=\"-489.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16, 1, 3, 3)</text>\n</g>\n<!-- 139999076736360&#45;&gt;139999076734400 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139999076736360&#45;&gt;139999076734400</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.9872,-481.9832C56.3524,-473.6737 62.8346,-463.6342 68.3998,-455.015\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"71.4985,-456.6682 73.9824,-446.3687 65.6177,-452.8712 71.4985,-456.6682\"/>\n</g>\n<!-- 139999076733448 -->\n<g id=\"node10\" class=\"node\">\n<title>139999076733448</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"150,-516 96,-516 96,-482 150,-482 150,-516\"/>\n<text text-anchor=\"middle\" x=\"123\" y=\"-502.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">0.bias</text>\n<text text-anchor=\"middle\" x=\"123\" y=\"-489.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16)</text>\n</g>\n<!-- 139999076733448&#45;&gt;139999076734400 -->\n<g id=\"edge9\" class=\"edge\">\n<title>139999076733448&#45;&gt;139999076734400</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M111.7448,-481.9832C106.1903,-473.5853 99.467,-463.4204 93.7259,-454.7404\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"96.6247,-452.7785 88.1887,-446.3687 90.7862,-456.6402 96.6247,-452.7785\"/>\n</g>\n<!-- 139999076733224 -->\n<g id=\"node11\" class=\"node\">\n<title>139999076733224</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"227.5,-389 146.5,-389 146.5,-355 227.5,-355 227.5,-389\"/>\n<text text-anchor=\"middle\" x=\"187\" y=\"-375.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">2.weight</text>\n<text text-anchor=\"middle\" x=\"187\" y=\"-362.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16, 16, 3, 3)</text>\n</g>\n<!-- 139999076733224&#45;&gt;139998945739272 -->\n<g id=\"edge10\" class=\"edge\">\n<title>139999076733224&#45;&gt;139998945739272</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M187,-354.9832C187,-347.1157 187,-337.6973 187,-329.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"190.5001,-329.3686 187,-319.3687 183.5001,-329.3687 190.5001,-329.3686\"/>\n</g>\n<!-- 139999076735016 -->\n<g id=\"node12\" class=\"node\">\n<title>139999076735016</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"300,-389 246,-389 246,-355 300,-355 300,-389\"/>\n<text text-anchor=\"middle\" x=\"273\" y=\"-375.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">2.bias</text>\n<text text-anchor=\"middle\" x=\"273\" y=\"-362.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16)</text>\n</g>\n<!-- 139999076735016&#45;&gt;139998945739272 -->\n<g id=\"edge11\" class=\"edge\">\n<title>139999076735016&#45;&gt;139998945739272</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M249.9536,-354.9832C237.4217,-345.73 221.9845,-334.3316 209.5333,-325.1379\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"211.5864,-322.3032 201.4627,-319.1788 207.4283,-327.9345 211.5864,-322.3032\"/>\n</g>\n<!-- 139998945740896 -->\n<g id=\"node13\" class=\"node\">\n<title>139998945740896</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"333.5,-262 252.5,-262 252.5,-228 333.5,-228 333.5,-262\"/>\n<text text-anchor=\"middle\" x=\"293\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">4.weight</text>\n<text text-anchor=\"middle\" x=\"293\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (10, 16, 3, 3)</text>\n</g>\n<!-- 139998945740896&#45;&gt;139998945740280 -->\n<g id=\"edge12\" class=\"edge\">\n<title>139998945740896&#45;&gt;139998945740280</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M293,-227.9832C293,-220.1157 293,-210.6973 293,-202.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"296.5001,-202.3686 293,-192.3687 289.5001,-202.3687 296.5001,-202.3686\"/>\n</g>\n<!-- 139998945740392 -->\n<g id=\"node14\" class=\"node\">\n<title>139998945740392</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"406,-262 352,-262 352,-228 406,-228 406,-262\"/>\n<text text-anchor=\"middle\" x=\"379\" y=\"-248.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">4.bias</text>\n<text text-anchor=\"middle\" x=\"379\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (10)</text>\n</g>\n<!-- 139998945740392&#45;&gt;139998945740280 -->\n<g id=\"edge13\" class=\"edge\">\n<title>139998945740392&#45;&gt;139998945740280</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M355.9536,-227.9832C343.4217,-218.73 327.9845,-207.3316 315.5333,-198.1379\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"317.5864,-195.3032 307.4627,-192.1788 313.4283,-200.9345 317.5864,-195.3032\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCq-ye_VtMbX"
      },
      "source": [
        "<img src=\"https://miro.medium.com/max/1280/1*Eg-4u0I7HGZlZmPYeeUYWA.jpeg\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LSELFh2uJJo"
      },
      "source": [
        "# NEXT UP - Deeper\n",
        "\n",
        "<img src=\"https://miro.medium.com/proxy/1*KBobA-DaVtQ8Px6P_-tNqQ.jpeg\" width=400 />\n",
        "\n",
        "These better be helping!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptHXG54Vvulm"
      },
      "source": [
        "## What is Deep Learning Anyway?"
      ]
    }
  ]
}